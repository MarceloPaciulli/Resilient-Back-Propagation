# Resilient-Back-Propagation
Training a neural network is the process of finding values for the weights and biases so that, for a set of training data with known input and output values, the computed outputs of the network closely match the known outputs. The most common technique used to train Neural Networks is the back-propagation algorithm. Back propagation requires a value for a hyperparameter called the learning rate. The effectiveness of back propagation is highly sensitive to the value of the learning rate. Rprop (Resilient backpropagation) was created by Martin Riedmiller and Heinrich Braun in 1992.

### Artificial Neural Network - Responses
![ann_responses](https://github.com/MarceloPaciulli/Resilient-Back-Propagation/assets/93230178/810a4ad7-d556-42cb-a66b-e990aa21f1c5)

